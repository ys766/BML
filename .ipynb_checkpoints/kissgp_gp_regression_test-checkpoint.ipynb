{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from matplotlib import pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training data: let's try to learn a sine function, but with KISS-GP let's use 100 training examples.\n",
    "def make_data(cuda=False):\n",
    "    train_x = Variable(torch.linspace(0, 1, 500))\n",
    "    train_y = Variable(torch.sin(train_x.data * (2 * math.pi)))\n",
    "    test_x = Variable(torch.linspace(0, 1, 100))\n",
    "    test_y = Variable(torch.sin(test_x.data * (2 * math.pi)))\n",
    "    if cuda:\n",
    "        train_x = train_x.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "        test_x = test_x.cuda()\n",
    "        test_y = test_y.cuda()\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(uid1, vid1, uid2, vid2):\n",
    "    user1 = user_feature[uid1]\n",
    "    user2 = user_feature[uid2]\n",
    "    movie1 = movie_feature[vid1]\n",
    "    movie2 = movie_feature[vid2]\n",
    "    sum = 0\n",
    "    for i in range(0, 28):\n",
    "        if user1[i] != user2[i]:\n",
    "            sum += 1\n",
    "    for i in range(0, 19):\n",
    "        if movie1[i] != movie2[i]:\n",
    "            sum += 1\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def build_sparse_W(pattern = 'train'):\n",
    "#Create sparse matrix self.W based on:\n",
    "#1.self.indexed_training_set or self.indexed_testing_set\n",
    "    #2.self.indexed_inducing_set\n",
    "    #call choose_inducing_point before calling this method\n",
    "    if pattern == 'train':\n",
    "        X = indexed_training_set\n",
    "    elif pattern == 'test':\n",
    "        X = indexed_testing_set\n",
    "    U = indexed_inducing_set\n",
    "    n = len(X)\n",
    "    m = len(U)\n",
    "    W = np.matrix(np.zeros([n,m]))\n",
    "    for i in range(n):\n",
    "        low_1,low_2,index_1,index_2 = [47,47,-1,-1]\n",
    "        for j in range(m):\n",
    "            ui,uj = X[i][0],U[j][0]\n",
    "            vi,vj = X[i][1],U[j][1]\n",
    "            buffer = distance(ui, vi, uj, vj)\n",
    "            if buffer <= low_1:\n",
    "                low_2 = low_1\n",
    "                low_1 = buffer\n",
    "                index_2 = index_1\n",
    "                index_1 = j\n",
    "                if low_1 == 0 and low_2 == 0:\n",
    "                    break\n",
    "        if low_1 == low_2:\n",
    "            W[i,[index_1,index_2]] = 0.5\n",
    "        else:\n",
    "            W[i,[index_1,index_2]] = np.array([low_2,low_1])/(low_2 + low_1)\n",
    "    if pattern == 'train':\n",
    "        training_W = W\n",
    "    elif pattern == 'test':\n",
    "        testing_W = W\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_inducing_point(ratio,pattern = 'random',source = 'training set'):\n",
    "    # function used to choose inducing point from self.training_set\n",
    "    # ratio: inducing_point/data_size\n",
    "    # Extra choosing method could be changed by pattern\n",
    "    if pattern == 'random' and source == 'training set':\n",
    "        n = train_reduced.shape[0]\n",
    "        m = np.ceil(n*ratio).astype(int)\n",
    "        indexed_inducing_set = train_reduced[np.random.choice(n,m,replace = False)]\n",
    "    return indexed_inducing_set\n",
    "\n",
    "def build_Kuu(a1,b1,a2,b2):\n",
    "    m = indexed_inducing_set.shape[0]\n",
    "    Kuu = np.zeros((m,m), dtype = np.int)\n",
    "    for i in range(0,m):\n",
    "        uid1 = indexed_inducing_set[i][0]\n",
    "        vid1 = indexed_inducing_set[i][1]\n",
    "        user1 = user_feature[uid1]\n",
    "        movie1 = movie_feature[vid1]\n",
    "        for j in range(i,m):\n",
    "            uid2 = indexed_inducing_set[j][0]\n",
    "            vid2 = indexed_inducing_set[j][1]\n",
    "            user2 = user_feature[uid2]\n",
    "            movie2 = movie_feature[vid2]\n",
    "            k_side_user = np.dot(np.reshape(user1,(1, 28)), np.reshape(user2,(28,1)))\n",
    "            k_side_movie = np.dot(np.reshape(movie1,(1, 19)), np.reshape(movie2,(19,1)))\n",
    "            k_user = 0\n",
    "            k_movie = 0\n",
    "            \n",
    "            if uid1 == uid2:\n",
    "                k_user += a1 * a1\n",
    "            k_user += b1 * b1 * k_side_user\n",
    "            \n",
    "            if vid1 == vid2:\n",
    "                k_movie += a2 * a2\n",
    "            k_movie += b2 * b2 * k_side_movie\n",
    "            \n",
    "            Kuu[i][j] = np.dot(k_user, k_movie)\n",
    "            Kuu[j][i] = Kuu[i][j]\n",
    "            \n",
    "    return Kuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''inducePointLocation: (uid,vid) m by 2\n",
    "w is the weight matrix n by m\n",
    "sigma_squared: noise\n",
    "y : n by 1\n",
    "return value: y'*(K+Sig^2I)^-1*y\n",
    "'''\n",
    "user_feature = np.loadtxt(\"user_feature.csv\", dtype = int)\n",
    "movie_feature = np.loadtxt(\"movie_feature.csv\", dtype = int)\n",
    "def woodbury_inversion(inducePointLocation):\n",
    "    w = build_sparse_W()\n",
    "    def hyper(x, w, y):\n",
    "        a1 = x[0]\n",
    "        b1 = x[1]\n",
    "        a2 = x[2]\n",
    "        b2 = x[3]\n",
    "        sigma_squared = x[4]\n",
    "        kuu = build_Kuu(a1,b1,a2,b2)\n",
    "        inv_kuu = np.linalg.inv(kuu)\n",
    "        b = np.linalg.inv(inv_kuu + 1 / sigma_squared * w.transpose() * w)\n",
    "        a = 1 / sigma_squared * w\n",
    "        n = np.size(a,0)\n",
    "        m = np.size(b,1)\n",
    "        temp_res = np.zeros((,n), dtype = np.int)\n",
    "        for i in range(0, n):\n",
    "            res = np.zeros((n,), dtype = np.int)\n",
    "            prod = np.zeros((m,), dtype = np.int)\n",
    "            for j in range(0, m):\n",
    "                prod[j] = a[i] * b[:,j]\n",
    "            for k in range(0, n):\n",
    "                res[k] = prod * a[k, :].transpose()\n",
    "            temp_res[i] = res * y\n",
    "        \n",
    "        return (y.transpose() * y / sigma_squared - y.transpose() * temp_res)\n",
    "    return hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductKernel(Kernel):\n",
    "    def __init__(self, a1_bound=(0, 10), a2_bound=(0, 10), eps=1e-5):\n",
    "        super(ProductKernel, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1_bound)\n",
    "        self.register_parameter('a2', nn.Parameter(torch.zeros(1, 1)), a2_bound)\n",
    "#         self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1__bound)\n",
    "#         self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1__bound)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        n, d = x1.size()\n",
    "        m, _ = x2.size()\n",
    "\n",
    "        \n",
    "        res = 2 * x1.matmul(x2.transpose(0, 1))\n",
    "\n",
    "        x1_squared = torch.bmm(x1.view(n, 1, d), x1.view(n, d, 1))\n",
    "        x1_squared = x1_squared.view(n, 1).expand(n, m)\n",
    "        x2_squared = torch.bmm(x2.view(m, 1, d), x2.view(m, d, 1))\n",
    "        x2_squared = x2_squared.view(1, m).expand(n, m)\n",
    "        res.sub_(x1_squared).sub_(x2_squared)  # res = -(x - z)^2\n",
    "\n",
    "        res = res / (self.log_lengthscale.exp() + self.eps)  # res = -(x - z)^2 / lengthscale\n",
    "        res.exp_()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tests that pass with the exact kernel should pass with the interpolated kernel.\n",
    "class LatentFunction(gpytorch.GridInducingPointModule):\n",
    "    def __init__(self):\n",
    "        super(LatentFunction, self).__init__(grid_size=100, grid_bounds=[(0,500),(0, 800)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPRegressionModel, self).__init__(GaussianLikelihood())\n",
    "        self.latent_function = LatentFunction()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.latent_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y):\n",
    "    gp_model = GPRegressionModel()\n",
    "\n",
    "    # Optimize the model\n",
    "    gp_model.train()\n",
    "    optimizer = optim.Adam(gp_model.parameters(), lr=0.1)\n",
    "    optimizer.n_iter = 0\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        optimizer.zero_grad()\n",
    "        output = gp_model(train_x)\n",
    "        loss = -gp_model.marginal_log_likelihood(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.n_iter += 1\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test the model\n",
    "    gp_model.eval()\n",
    "    gp_model.condition(train_x, train_y)\n",
    "    test_preds = gp_model(test_x).mean()\n",
    "    mean_abs_error = torch.mean(torch.abs(test_y - test_preds))\n",
    "    print(mean_abs_error.data.squeeze()[0])\n",
    "\n",
    "#     assert(mean_abs_error.data.squeeze()[0] < 0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44149\n",
      "4367\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "train_reduced = []\n",
    "test_reduced = []\n",
    "\n",
    "training_b = np.loadtxt(\"ubbase.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "test_b = np.loadtxt(\"ubtest.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "\n",
    "for i in range(0, training_b.shape[0]):\n",
    "    if training_b[i][0] <= 500 and training_b[i][1] <= 800:\n",
    "        train_reduced.append(training_b[i])\n",
    "\n",
    "for i in range(0, test_b.shape[0]):\n",
    "    if test_b[i][0] <= 500 and test_b[i][1] <= 800:\n",
    "        test_reduced.append(test_b[i])\n",
    "\n",
    "train_reduced = np.asarray(train_reduced)\n",
    "test_reduced = np.asarray(test_reduced)\n",
    "\n",
    "print(len(train_reduced))\n",
    "print(len(test_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n",
      "(1, 1)\n",
      "454\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "393\n",
      "(1, 1)\n",
      "169\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "115\n",
      "(1, 1)\n",
      "13\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "405\n",
      "(1, 1)\n",
      "787\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "59\n",
      "(1, 1)\n",
      "618\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "379\n",
      "(1, 1)\n",
      "183\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "327\n",
      "(1, 1)\n",
      "238\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "296\n",
      "(1, 1)\n",
      "284\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "6\n",
      "(1, 1)\n",
      "516\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "271\n",
      "(1, 1)\n",
      "610\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "250\n",
      "(1, 1)\n",
      "100\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "56\n",
      "(1, 1)\n",
      "67\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "459\n",
      "(1, 1)\n",
      "696\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "305\n",
      "(1, 1)\n",
      "184\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "275\n",
      "(1, 1)\n",
      "229\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "293\n",
      "(1, 1)\n",
      "685\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "380\n",
      "(1, 1)\n",
      "443\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "331\n",
      "(1, 1)\n",
      "175\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "178\n",
      "(1, 1)\n",
      "751\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "301\n",
      "(1, 1)\n",
      "204\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "75\n",
      "(1, 1)\n",
      "322\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "417\n",
      "(1, 1)\n",
      "597\n",
      "(1, 1)\n",
      "493\n",
      "(1, 1)\n",
      "404\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "(23, 23)\n"
     ]
    }
   ],
   "source": [
    "global user_feature \n",
    "user_feature = []\n",
    "with open(\"user_feature.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        user_feature.append(row)\n",
    "    user_feature = np.array(user_feature, dtype = np.int)\n",
    "    \n",
    "#user_feature = np.loadtxt(\"user_feature.csv\", dtype = np.int)\n",
    "global movie_feature \n",
    "movie_feature = []\n",
    "with open(\"movie_feature.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        movie_feature.append(row)\n",
    "    movie_feature = np.array(movie_feature, dtype = np.int)\n",
    "    \n",
    "global indexed_inducing_set \n",
    "indexed_inducing_set = choose_inducing_point(0.0005)\n",
    "K = build_Kuu(0.3, 1, 1.5,3)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "print(K)\n",
    "print(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_kissgp_gp_mean_abs_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-859532636d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_kissgp_gp_mean_abs_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_kissgp_gp_mean_abs_error' is not defined"
     ]
    }
   ],
   "source": [
    "train_x = torch.from_numpy(train_reduced[:,0:2])\n",
    "train_x = train_x.float()\n",
    "train_x = Variable(train_x)\n",
    "\n",
    "train_y = torch.from_numpy(train_reduced[:,-1])\n",
    "train_y = train_y.float()\n",
    "train_y = Variable(train_y)\n",
    "\n",
    "test_x = torch.from_numpy(test_reduced[:,0:2])\n",
    "test_x = test_x.float()\n",
    "test_x = Variable(test_x)\n",
    "\n",
    "test_y = torch.from_numpy(test_reduced[:,-1])\n",
    "test_y = test_y.float()\n",
    "test_y = Variable(test_y)\n",
    "\n",
    "test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((5,1))\n",
    "print(a.shape)\n",
    "b = np.reshape(a,(1,5))\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
