{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training data: let's try to learn a sine function, but with KISS-GP let's use 100 training examples.\n",
    "def make_data(cuda=False):\n",
    "    train_x = Variable(torch.linspace(0, 1, 500))\n",
    "    train_y = Variable(torch.sin(train_x.data * (2 * math.pi)))\n",
    "    test_x = Variable(torch.linspace(0, 1, 100))\n",
    "    test_y = Variable(torch.sin(test_x.data * (2 * math.pi)))\n",
    "    if cuda:\n",
    "        train_x = train_x.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "        test_x = test_x.cuda()\n",
    "        test_y = test_y.cuda()\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_W(pattern = 'train'):\n",
    "#Create sparse matrix self.W based on:\n",
    "#1.self.indexed_training_set or self.indexed_testing_set\n",
    "    #2.self.indexed_inducing_set\n",
    "    #call choose_inducing_point before calling this method\n",
    "    if pattern == 'train':\n",
    "        X = indexed_training_set\n",
    "    elif pattern == 'test':\n",
    "        X = indexed_testing_set\n",
    "    U = indexed_inducing_set\n",
    "    n = len(X)\n",
    "    m = len(U)\n",
    "    W = np.matrix(np.zeros([m,n]))\n",
    "    for i in range(n):\n",
    "        low_1,low_2,index_1,index_2 = [47,47,-1,-1]\n",
    "        for j in range(m):\n",
    "            ui,uj = X[i][0],U[j][0]\n",
    "            vi,vj = X[i][1],U[j][1]\n",
    "            buffer = self.user_distance[ui-1,uj-1] + self.movie_distance[vi-1,vj-1]\n",
    "            if buffer <= low_1:\n",
    "                low_2 = low_1\n",
    "                low_1 = buffer\n",
    "                index_2 = index_1\n",
    "                index_1 = j\n",
    "                if low_1 == 0 and low_2 == 0:\n",
    "                    break\n",
    "        if low_1 == low_2:\n",
    "            W[i,[index_1,index_2]] = 0.5\n",
    "        else:\n",
    "            W[i,[index_1,index_2]] = np.array([low_2,low_1])/(low_2 + low_1)\n",
    "    if pattern == 'train':\n",
    "        self.training_W = W\n",
    "    elif pattern == 'test':\n",
    "        self.testing_W = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''inducePointLocation: (uid,vid) m by 2\n",
    "w is the weight matrix n by m\n",
    "sigma_squared: noise\n",
    "y : n by 1\n",
    "return value: y'*(K+Sig^2I)^-1*y\n",
    "'''\n",
    "user_feature = np.loadtxt(\"user_feature.csv\", dtype = int)\n",
    "movie_feature = np.loadtxt(\"movie_feature.csv\", dtype = int)\n",
    "def woodbury_inversion(inducePointLocation):\n",
    "    w = build_sparse_W()\n",
    "    def hyper(x, w, y):\n",
    "        a1 = x[0]\n",
    "        b1 = x[1]\n",
    "        a2 = x[2]\n",
    "        b2 = x[3]\n",
    "        sigma_squared = x[4]\n",
    "        kuu = build_Kuu(a1,b1,a2,b2)\n",
    "        inv_kuu = np.linalg.inv(kuu)\n",
    "        b = np.linalg.inv(inv_kuu + 1 / sigma_squared * w.transpose() * w)\n",
    "        a = 1 / sigma_squared * w\n",
    "        n = np.size(a,0)\n",
    "        m = np.size(b,1)\n",
    "        temp_res = np.zeros((,n), dtype = np.int)\n",
    "        for i in range(0, n):\n",
    "            res = np.zeros((n,), dtype = np.int)\n",
    "            prod = np.zeros((m,), dtype = np.int)\n",
    "            for j in range(0, m):\n",
    "                prod[j] = a[i] * b[:,j]\n",
    "            for k in range(0, n):\n",
    "                res[k] = prod * a[k, :].transpose()\n",
    "            temp_res[i] = res * y\n",
    "        \n",
    "        return (y.transpose() * y / sigma_squared - y.transpose() * temp_res)\n",
    "    return hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductKernel(Kernel):\n",
    "    def __init__(self, a1_bound=(0, 10), a2_bound=(0, 10), eps=1e-5):\n",
    "        super(ProductKernel, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1_bound)\n",
    "        self.register_parameter('a2', nn.Parameter(torch.zeros(1, 1)), a2_bound)\n",
    "#         self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1__bound)\n",
    "#         self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1__bound)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        n, d = x1.size()\n",
    "        m, _ = x2.size()\n",
    "\n",
    "        \n",
    "        res = 2 * x1.matmul(x2.transpose(0, 1))\n",
    "\n",
    "        x1_squared = torch.bmm(x1.view(n, 1, d), x1.view(n, d, 1))\n",
    "        x1_squared = x1_squared.view(n, 1).expand(n, m)\n",
    "        x2_squared = torch.bmm(x2.view(m, 1, d), x2.view(m, d, 1))\n",
    "        x2_squared = x2_squared.view(1, m).expand(n, m)\n",
    "        res.sub_(x1_squared).sub_(x2_squared)  # res = -(x - z)^2\n",
    "\n",
    "        res = res / (self.log_lengthscale.exp() + self.eps)  # res = -(x - z)^2 / lengthscale\n",
    "        res.exp_()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tests that pass with the exact kernel should pass with the interpolated kernel.\n",
    "class LatentFunction(gpytorch.GridInducingPointModule):\n",
    "    def __init__(self):\n",
    "        super(LatentFunction, self).__init__(grid_size=100, grid_bounds=[(0,500),(0, 800)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPRegressionModel, self).__init__(GaussianLikelihood())\n",
    "        self.latent_function = LatentFunction()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.latent_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y):\n",
    "    gp_model = GPRegressionModel()\n",
    "\n",
    "    # Optimize the model\n",
    "    gp_model.train()\n",
    "    optimizer = optim.Adam(gp_model.parameters(), lr=0.1)\n",
    "    optimizer.n_iter = 0\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        optimizer.zero_grad()\n",
    "        output = gp_model(train_x)\n",
    "        loss = -gp_model.marginal_log_likelihood(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.n_iter += 1\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test the model\n",
    "    gp_model.eval()\n",
    "    gp_model.condition(train_x, train_y)\n",
    "    test_preds = gp_model(test_x).mean()\n",
    "    mean_abs_error = torch.mean(torch.abs(test_y - test_preds))\n",
    "    print(mean_abs_error.data.squeeze()[0])\n",
    "\n",
    "#     assert(mean_abs_error.data.squeeze()[0] < 0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44149\n",
      "4367\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "train_reduced = []\n",
    "test_reduced = []\n",
    "\n",
    "training_b = np.loadtxt(\"ubbase.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "test_b = np.loadtxt(\"ubtest.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "\n",
    "for i in range(0, training_b.shape[0]):\n",
    "    if training_b[i][0] <= 500 and training_b[i][1] <= 800:\n",
    "        train_reduced.append(training_b[i])\n",
    "\n",
    "for i in range(0, test_b.shape[0]):\n",
    "    if test_b[i][0] <= 500 and test_b[i][1] <= 800:\n",
    "        test_reduced.append(test_b[i])\n",
    "\n",
    "train_reduced = np.asarray(train_reduced)\n",
    "test_reduced = np.asarray(test_reduced)\n",
    "\n",
    "print(len(train_reduced))\n",
    "print(len(test_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "1.5409389734268188\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.from_numpy(train_reduced[:,0:2])\n",
    "train_x = train_x.float()\n",
    "train_x = Variable(train_x)\n",
    "\n",
    "train_y = torch.from_numpy(train_reduced[:,-1])\n",
    "train_y = train_y.float()\n",
    "train_y = Variable(train_y)\n",
    "\n",
    "test_x = torch.from_numpy(test_reduced[:,0:2])\n",
    "test_x = test_x.float()\n",
    "test_x = Variable(test_x)\n",
    "\n",
    "test_y = torch.from_numpy(test_reduced[:,-1])\n",
    "test_y = test_y.float()\n",
    "test_y = Variable(test_y)\n",
    "\n",
    "test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
