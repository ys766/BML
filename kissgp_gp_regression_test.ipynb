{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple training data: let's try to learn a sine function, but with KISS-GP let's use 100 training examples.\n",
    "def make_data(cuda=False):\n",
    "    train_x = Variable(torch.linspace(0, 1, 50000))\n",
    "    train_y = Variable(torch.sin(train_x.data * (2 * math.pi)))\n",
    "    test_x = Variable(torch.linspace(0, 1, 510))\n",
    "    test_y = Variable(torch.sin(test_x.data * (2 * math.pi)))\n",
    "    if cuda:\n",
    "        train_x = train_x.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "        test_x = test_x.cuda()\n",
    "        test_y = test_y.cuda()\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All tests that pass with the exact kernel should pass with the interpolated kernel.\n",
    "class LatentFunction(gpytorch.GridInducingPointModule):\n",
    "    def __init__(self):\n",
    "        super(LatentFunction, self).__init__(grid_size=100, grid_bounds=[(0,1000), (0, 2000)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPRegressionModel, self).__init__(GaussianLikelihood())\n",
    "        self.latent_function = LatentFunction()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.latent_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y):\n",
    "    gp_model = GPRegressionModel()\n",
    "\n",
    "    # Optimize the model\n",
    "    gp_model.train()\n",
    "    optimizer = optim.Adam(gp_model.parameters(), lr=0.1)\n",
    "    optimizer.n_iter = 0\n",
    "    for i in range(25):\n",
    "        optimizer.zero_grad()\n",
    "        output = gp_model(train_x)\n",
    "        loss = -gp_model.marginal_log_likelihood(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.n_iter += 1\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test the model\n",
    "    gp_model.eval()\n",
    "    gp_model.condition(train_x, train_y)\n",
    "    test_preds = gp_model(test_x).mean()\n",
    "    mean_abs_error = torch.mean(torch.abs(test_y - test_preds))\n",
    "    print(mean_abs_error.data.squeeze()[0])\n",
    "\n",
    "#     assert(mean_abs_error.data.squeeze()[0] < 0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "training_b = np.loadtxt(\"ubbase.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "test_b = np.loadtxt(\"ubtest.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "\n",
    "train_x = torch.from_numpy(training_b[:\n",
    "                                      ,0:2])\n",
    "train_x = train_x.float()\n",
    "train_x = Variable(train_x)\n",
    "\n",
    "train_y = torch.from_numpy(training_b[:,-1])\n",
    "train_y = train_y.float()\n",
    "train_y = Variable(train_y)\n",
    "\n",
    "test_x = torch.from_numpy(test_b[:,0:2])\n",
    "test_x = test_x.float()\n",
    "test_x = Variable(test_x)\n",
    "\n",
    "test_y = torch.from_numpy(test_b[:,-1])\n",
    "test_y = test_y.float()\n",
    "test_y = Variable(test_y)\n",
    "\n",
    "test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
