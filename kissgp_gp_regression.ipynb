{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from matplotlib import pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple training data: let's try to learn a sine function, but with KISS-GP let's use 100 training examples.\n",
    "def make_data(cuda=False):\n",
    "    train_x = Variable(torch.linspace(0, 1, 500))\n",
    "    train_y = Variable(torch.sin(train_x.data * (2 * math.pi)))\n",
    "    test_x = Variable(torch.linspace(0, 1, 100))\n",
    "    test_y = Variable(torch.sin(test_x.data * (2 * math.pi)))\n",
    "    if cuda:\n",
    "        train_x = train_x.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "        test_x = test_x.cuda()\n",
    "        test_y = test_y.cuda()\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(uid1, vid1, uid2, vid2):\n",
    "    user1 = user_feature[uid1]\n",
    "    user2 = user_feature[uid2]\n",
    "    movie1 = movie_feature[vid1]\n",
    "    movie2 = movie_feature[vid2]\n",
    "    sum = 0\n",
    "    for i in range(0, 28):\n",
    "        if user1[i] != user2[i]:\n",
    "            sum += 1\n",
    "    for i in range(0, 19):\n",
    "        if movie1[i] != movie2[i]:\n",
    "            sum += 1\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def build_sparse_W(pattern = 'train'):\n",
    "#Create sparse matrix self.W based on:\n",
    "#1.self.indexed_training_set or self.indexed_testing_set\n",
    "    #2.self.indexed_inducing_set\n",
    "    #call choose_inducing_point before calling this method\n",
    "    if pattern == 'train':\n",
    "        X = train_reduced\n",
    "    elif pattern == 'test':\n",
    "        X = indexed_testing_set\n",
    "    U = indexed_inducing_set\n",
    "    n = len(X)\n",
    "    m = len(U)\n",
    "    W = np.matrix(np.zeros([n,m]))\n",
    "    for i in range(n):\n",
    "        low_1,low_2,index_1,index_2 = [47,47,-1,-1]\n",
    "        for j in range(m):\n",
    "            ui,uj = X[i][0],U[j][0]\n",
    "            vi,vj = X[i][1],U[j][1]\n",
    "            buffer = distance(ui, vi, uj, vj)\n",
    "            if buffer <= low_1:\n",
    "                low_2 = low_1\n",
    "                low_1 = buffer\n",
    "                index_2 = index_1\n",
    "                index_1 = j\n",
    "                if low_1 == 0 and low_2 == 0:\n",
    "                    break\n",
    "        if low_1 == low_2:\n",
    "            W[i,[index_1,index_2]] = 0.5\n",
    "        else:\n",
    "            W[i,[index_1,index_2]] = np.array([low_2,low_1])/(low_2 + low_1)\n",
    "    if pattern == 'train':\n",
    "        training_W = W\n",
    "    elif pattern == 'test':\n",
    "        testing_W = W\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_inducing_point(ratio,pattern = 'random',source = 'training set'):\n",
    "    # function used to choose inducing point from self.training_set\n",
    "    # ratio: inducing_point/data_size\n",
    "    # Extra choosing method could be changed by pattern\n",
    "    if pattern == 'random' and source == 'training set':\n",
    "        n = train_reduced.shape[0]\n",
    "        m = np.ceil(n*ratio).astype(int)\n",
    "        indexed_inducing_set = train_reduced[np.random.choice(n,m,replace = False)]\n",
    "    return indexed_inducing_set\n",
    "\n",
    "def build_Kuu(a1,b1,a2,b2):\n",
    "    m = indexed_inducing_set.shape[0]\n",
    "    Kuu = np.zeros((m,m), dtype = np.int)\n",
    "    for i in range(0,m):\n",
    "        uid1 = indexed_inducing_set[i][0]\n",
    "        vid1 = indexed_inducing_set[i][1]\n",
    "        user1 = user_feature[uid1]\n",
    "        movie1 = movie_feature[vid1]\n",
    "        for j in range(i,m):\n",
    "            uid2 = indexed_inducing_set[j][0]\n",
    "            vid2 = indexed_inducing_set[j][1]\n",
    "            user2 = user_feature[uid2]\n",
    "            movie2 = movie_feature[vid2]\n",
    "            k_side_user = np.dot(np.reshape(user1,(1, 28)), np.reshape(user2,(28,1)))\n",
    "            k_side_movie = np.dot(np.reshape(movie1,(1, 19)), np.reshape(movie2,(19,1)))\n",
    "            k_user = 0\n",
    "            k_movie = 0\n",
    "            \n",
    "            if uid1 == uid2:\n",
    "                k_user += a1 * a1\n",
    "            k_user += b1 * b1 * k_side_user\n",
    "            \n",
    "            if vid1 == vid2:\n",
    "                k_movie += a2 * a2\n",
    "            k_movie += b2 * b2 * k_side_movie\n",
    "            \n",
    "            Kuu[i][j] = np.dot(k_user, k_movie)\n",
    "            Kuu[j][i] = Kuu[i][j]\n",
    "            \n",
    "    return Kuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''inducePointLocation: (uid,vid) m by 2\n",
    "w is the weight matrix n by m\n",
    "sigma_squared: noise\n",
    "y : n by 1\n",
    "return value: (K+Sig^2I)^-1*y\n",
    "'''\n",
    "user_feature = np.loadtxt(\"user_feature.csv\", dtype = int)\n",
    "movie_feature = np.loadtxt(\"movie_feature.csv\", dtype = int)\n",
    "def woodbury_inversion(inducePointLocation):\n",
    "    w = build_sparse_W()\n",
    "    def hyper(x, w, y):\n",
    "        a1 = x[0]\n",
    "        b1 = x[1]\n",
    "        a2 = x[2]\n",
    "        b2 = x[3]\n",
    "        sigma_squared = x[4]\n",
    "        kuu = build_Kuu(a1,b1,a2,b2)\n",
    "        inv_kuu = np.linalg.inv(kuu)\n",
    "        b = np.linalg.inv(inv_kuu + 1 / sigma_squared * w.transpose() * w)\n",
    "        a = 1 / sigma_squared * w\n",
    "        n = np.size(a,0)\n",
    "        m = np.size(b,1)\n",
    "        temp_res = np.zeros((,n), dtype = np.int)\n",
    "        for i in range(0, n):\n",
    "            res = np.zeros((n,), dtype = np.int)\n",
    "            prod = np.zeros((m,), dtype = np.int)\n",
    "            for j in range(0, m):\n",
    "                prod[j] = a[i] * b[:,j]\n",
    "            for k in range(0, n):\n",
    "                res[k] = prod * a[k, :].transpose()\n",
    "            temp_res[i] = res * y\n",
    "        \n",
    "        return (y / sigma_squared - temp_res)\n",
    "    return hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProductKernel(Kernel):\n",
    "    def __init__(self, a1_bound=(0, 10), a2_bound=(0, 10), eps=1e-5):\n",
    "        super(ProductKernel, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1_bound)\n",
    "        self.register_parameter('a2', nn.Parameter(torch.zeros(1, 1)), a2_bound)\n",
    "#         self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1__bound)\n",
    "#         self.register_parameter('a1', nn.Parameter(torch.zeros(1, 1)), a1__bound)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        n, d = x1.size()\n",
    "        m, _ = x2.size()\n",
    "\n",
    "        \n",
    "        res = 2 * x1.matmul(x2.transpose(0, 1))\n",
    "\n",
    "        x1_squared = torch.bmm(x1.view(n, 1, d), x1.view(n, d, 1))\n",
    "        x1_squared = x1_squared.view(n, 1).expand(n, m)\n",
    "        x2_squared = torch.bmm(x2.view(m, 1, d), x2.view(m, d, 1))\n",
    "        x2_squared = x2_squared.view(1, m).expand(n, m)\n",
    "        res.sub_(x1_squared).sub_(x2_squared)  # res = -(x - z)^2\n",
    "\n",
    "        res = res / (self.log_lengthscale.exp() + self.eps)  # res = -(x - z)^2 / lengthscale\n",
    "        res.exp_()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All tests that pass with the exact kernel should pass with the interpolated kernel.\n",
    "class LatentFunction(gpytorch.GridInducingPointModule):\n",
    "    def __init__(self):\n",
    "        super(LatentFunction, self).__init__(grid_size=100, grid_bounds=[(0,500),(0, 800)])\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5, 1e-5])\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPRegressionModel, self).__init__(GaussianLikelihood())\n",
    "        self.latent_function = LatentFunction()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.latent_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y):\n",
    "    gp_model = GPRegressionModel()\n",
    "\n",
    "    # Optimize the model\n",
    "    gp_model.train()\n",
    "    optimizer = optim.Adam(gp_model.parameters(), lr=0.1)\n",
    "    optimizer.n_iter = 0\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        optimizer.zero_grad()\n",
    "        output = gp_model(train_x)\n",
    "        loss = -gp_model.marginal_log_likelihood(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.n_iter += 1\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test the model\n",
    "    gp_model.eval()\n",
    "    gp_model.condition(train_x, train_y)\n",
    "    test_preds = gp_model(test_x).mean()\n",
    "    mean_abs_error = torch.mean(torch.abs(test_y - test_preds))\n",
    "    print(mean_abs_error.data.squeeze()[0])\n",
    "\n",
    "#     assert(mean_abs_error.data.squeeze()[0] < 0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44149\n",
      "4367\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "train_reduced = []\n",
    "test_reduced = []\n",
    "\n",
    "training_b = np.loadtxt(\"ubbase.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "test_b = np.loadtxt(\"ubtest.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "\n",
    "for i in range(0, training_b.shape[0]):\n",
    "    if training_b[i][0] <= 500 and training_b[i][1] <= 800:\n",
    "        train_reduced.append(training_b[i])\n",
    "\n",
    "for i in range(0, test_b.shape[0]):\n",
    "    if test_b[i][0] <= 500 and test_b[i][1] <= 800:\n",
    "        test_reduced.append(test_b[i])\n",
    "\n",
    "train_reduced = np.asarray(train_reduced)\n",
    "test_reduced = np.asarray(test_reduced)\n",
    "\n",
    "print(len(train_reduced))\n",
    "print(len(test_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 45)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11809aa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44149, 45)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "global user_feature \n",
    "user_feature = []\n",
    "with open(\"user_feature.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        user_feature.append(row)\n",
    "    user_feature = np.array(user_feature, dtype = np.int)\n",
    "    \n",
    "#user_feature = np.loadtxt(\"user_feature.csv\", dtype = np.int)\n",
    "global movie_feature \n",
    "movie_feature = []\n",
    "with open(\"movie_feature.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        movie_feature.append(row)\n",
    "    movie_feature = np.array(movie_feature, dtype = np.int)\n",
    "    \n",
    "global indexed_inducing_set \n",
    "indexed_inducing_set = choose_inducing_point(0.001)\n",
    "K = build_Kuu(0, 5, 0, 2)\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "print(K.shape)\n",
    "plt.matshow(K)\n",
    "plt.show()\n",
    "W = build_sparse_W()\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(test_reduced,hyper):\n",
    "    a1 = hyper[0]\n",
    "    b1 = hyper[1]\n",
    "    a2 = hyper[2]\n",
    "    b2 = hyper[3]\n",
    "    Kuu = build_Kuu(a1,b1,a2,b2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_kissgp_gp_mean_abs_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-859532636d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_kissgp_gp_mean_abs_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_kissgp_gp_mean_abs_error' is not defined"
     ]
    }
   ],
   "source": [
    "train_x = torch.from_numpy(train_reduced[:,0:2])\n",
    "train_x = train_x.float()\n",
    "train_x = Variable(train_x)\n",
    "\n",
    "train_y = torch.from_numpy(train_reduced[:,-1])\n",
    "train_y = train_y.float()\n",
    "train_y = Variable(train_y)\n",
    "\n",
    "test_x = torch.from_numpy(test_reduced[:,0:2])\n",
    "test_x = test_x.float()\n",
    "test_x = Variable(test_x)\n",
    "\n",
    "test_y = torch.from_numpy(test_reduced[:,-1])\n",
    "test_y = test_y.float()\n",
    "test_y = Variable(test_y)\n",
    "\n",
    "test_kissgp_gp_mean_abs_error(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((5,1))\n",
    "print(a.shape)\n",
    "b = np.reshape(a,(1,5))\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
