{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(uid1, vid1, uid2, vid2):\n",
    "    user1 = user_feature[uid1]\n",
    "    user2 = user_feature[uid2]\n",
    "    movie1 = movie_feature[vid1]\n",
    "    movie2 = movie_feature[vid2]\n",
    "    sum = 0\n",
    "    for i in range(0, 28):\n",
    "        if user1[i] != user2[i]:\n",
    "            sum += 1\n",
    "    for i in range(0, 19):\n",
    "        if movie1[i] != movie2[i]:\n",
    "            sum += 1\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def build_sparse_W(X):\n",
    "#Create sparse matrix self.W based on:\n",
    "#1.self.indexed_training_set or self.indexed_testing_set\n",
    "    #2.self.indexed_inducing_set\n",
    "    #call choose_inducing_point before calling this method\n",
    "    U = indexed_inducing_set\n",
    "    n = len(X)\n",
    "    m = len(U)\n",
    "    W = np.matrix(np.zeros([n,m]))\n",
    "    for i in range(n):\n",
    "        low_1,low_2,index_1,index_2 = [47,47,-1,-1]\n",
    "        for j in range(m):\n",
    "            ui,uj = X[i][0],U[j][0]\n",
    "            vi,vj = X[i][1],U[j][1]\n",
    "            buffer = distance(ui, vi, uj, vj)\n",
    "            if buffer <= low_1:\n",
    "                low_2 = low_1\n",
    "                low_1 = buffer\n",
    "                index_2 = index_1\n",
    "                index_1 = j\n",
    "                if low_1 == 0 and low_2 == 0:\n",
    "                    break\n",
    "        if low_1 == low_2:\n",
    "            W[i,[index_1,index_2]] = 0.5\n",
    "        else:\n",
    "            W[i,[index_1,index_2]] = np.array([low_2,low_1])/(low_2 + low_1)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_inducing_point(ratio,pattern = 'random',source = 'training set'):\n",
    "    # function used to choose inducing point from self.training_set\n",
    "    # ratio: inducing_point/data_size\n",
    "    # Extra choosing method could be changed by pattern\n",
    "    if pattern == 'random' and source == 'training set':\n",
    "        n = train_reduced.shape[0]\n",
    "        m = np.ceil(n*ratio).astype(int)\n",
    "        indexed_inducing_set = train_reduced[np.random.choice(n,m,replace = False)]\n",
    "    return indexed_inducing_set\n",
    "\n",
    "def build_Kuu(a1,b1,a2,b2):\n",
    "    m = indexed_inducing_set.shape[0]\n",
    "    Kuu = np.zeros((m,m), dtype = np.int)\n",
    "    for i in range(0,m):\n",
    "        uid1 = indexed_inducing_set[i][0]\n",
    "        vid1 = indexed_inducing_set[i][1]\n",
    "        user1 = user_feature[uid1]\n",
    "        movie1 = movie_feature[vid1]\n",
    "        for j in range(i,m):\n",
    "            uid2 = indexed_inducing_set[j][0]\n",
    "            vid2 = indexed_inducing_set[j][1]\n",
    "            user2 = user_feature[uid2]\n",
    "            movie2 = movie_feature[vid2]\n",
    "            k_side_user = np.dot(np.reshape(user1,(1, 28)), np.reshape(user2,(28,1)))\n",
    "            k_side_movie = np.dot(np.reshape(movie1,(1, 19)), np.reshape(movie2,(19,1)))\n",
    "            k_user = 0\n",
    "            k_movie = 0\n",
    "            \n",
    "            if uid1 == uid2:\n",
    "                k_user += a1 * a1\n",
    "            k_user += b1 * b1 * k_side_user\n",
    "            \n",
    "            if vid1 == vid2:\n",
    "                k_movie += a2 * a2\n",
    "            k_movie += b2 * b2 * k_side_movie\n",
    "            \n",
    "            Kuu[i][j] = np.dot(k_user, k_movie)\n",
    "            Kuu[j][i] = Kuu[i][j]\n",
    "            \n",
    "    return Kuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''inducePointLocation: (uid,vid) m by 2\n",
    "w is the weight matrix n by m\n",
    "sigma_squared: noise\n",
    "y : n by 1\n",
    "return value: (K+Sig^2I)^-1*y\n",
    "'''\n",
    "def woodbury_inversion(x, w, y):\n",
    "    a1 = x[0]\n",
    "    b1 = x[1]\n",
    "    a2 = x[2]\n",
    "    b2 = x[3]\n",
    "    sigma_squared = x[4]\n",
    "    kuu = build_Kuu(a1,b1,a2,b2)\n",
    "    inv_kuu = np.linalg.inv(kuu)\n",
    "    b = np.linalg.inv(inv_kuu + 1 / sigma_squared * w.transpose() * w)\n",
    "    a = 1 / sigma_squared * w\n",
    "#         n = np.size(a,0)\n",
    "#         m = np.size(b,1)\n",
    "#         temp_res = np.zeros((,n), dtype = np.int)\n",
    "#         for i in range(0, n):\n",
    "#             res = np.zeros((n,), dtype = np.int)\n",
    "#             prod = np.zeros((m,), dtype = np.int)\n",
    "#             for j in range(0, m):\n",
    "#                 prod[j] = a[i] * b[:,j]\n",
    "#             for k in range(0, n):\n",
    "#                 res[k] = prod * a[k, :].transpose()\n",
    "#             temp_res[i] = res * y\n",
    "\n",
    "    return (y / sigma_squared - np.dot(np.dot(np.dot(a,b), a.transpose())), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(test_reduced,hyper):\n",
    "    a1 = hyper[0]\n",
    "    b1 = hyper[1]\n",
    "    a2 = hyper[2]\n",
    "    b2 = hyper[3]\n",
    "    Kuu = build_Kuu(a1,b1,a2,b2)\n",
    "    W = build_sparse_W(train_reduced)\n",
    "    inv_y = woodbury_inversion(hyper, W, train_reduced)\n",
    "    W_test = build_sparse_W(test_reduced)\n",
    "    y_pred = np.dot(np.dot(np.dot(W_test, Kuu), W), inv_y)\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44149\n",
      "4367\n"
     ]
    }
   ],
   "source": [
    "train_reduced = []\n",
    "test_reduced = []\n",
    "\n",
    "training_b = np.loadtxt(\"ubbase.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "test_b = np.loadtxt(\"ubtest.txt\", dtype = int, usecols=(0, 1, 2))\n",
    "\n",
    "for i in range(0, training_b.shape[0]):\n",
    "    if training_b[i][0] <= 500 and training_b[i][1] <= 800:\n",
    "        train_reduced.append(training_b[i])\n",
    "\n",
    "for i in range(0, test_b.shape[0]):\n",
    "    if test_b[i][0] <= 500 and test_b[i][1] <= 800:\n",
    "        test_reduced.append(test_b[i])\n",
    "\n",
    "train_reduced = np.asarray(train_reduced)\n",
    "test_reduced = np.asarray(test_reduced)\n",
    "\n",
    "print(len(train_reduced))\n",
    "print(len(test_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global user_feature \n",
    "user_feature = []\n",
    "with open(\"user_feature.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        user_feature.append(row)\n",
    "    user_feature = np.array(user_feature, dtype = np.int)\n",
    "    \n",
    "#user_feature = np.loadtxt(\"user_feature.csv\", dtype = np.int)\n",
    "global movie_feature \n",
    "movie_feature = []\n",
    "with open(\"movie_feature.csv\") as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        movie_feature.append(row)\n",
    "    movie_feature = np.array(movie_feature, dtype = np.int)\n",
    "    \n",
    "global indexed_inducing_set \n",
    "indexed_inducing_set = choose_inducing_point(0.001)\n",
    "hyper = [1,1,1,1,1]\n",
    "res = prediction(test_reduced, hyper)\n",
    "\n",
    "# K = build_Kuu(0, 5, 0, 2)\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "# print(K.shape)\n",
    "# plt.matshow(K)\n",
    "# plt.show()\n",
    "# W = build_sparse_W(train_reduced)\n",
    "# print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
